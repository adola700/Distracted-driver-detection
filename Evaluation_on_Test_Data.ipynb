{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V2wWpmYK2ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa75fb3e-6a2e-4767-d572-0e3b8a38f3ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847ZtHykKl0s"
      },
      "source": [
        "from numpy import *\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import joblib\n",
        "from IPython.display import Image\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten,Input\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDCYmpgEFz30"
      },
      "source": [
        "size = 128\n",
        "batch_size = 64\n",
        "channels = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVU7U_gvF7dP"
      },
      "source": [
        "import joblib\n",
        "X_test1 =joblib.load(\"/content/gdrive/MyDrive/project/X_test11.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoH9uJHvNpch"
      },
      "source": [
        "# VGG16 - model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wujpbtK6GAo7"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16, preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DPUZ8KwXIyf"
      },
      "source": [
        "!pip3 install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgb930jEWZc_"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f30vRhRK4JLY",
        "cellView": "code"
      },
      "source": [
        "#@title 0.43 log loss\n",
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "# re-size all the images to this\n",
        "# add preprocessing layer to the front of VGG\n",
        "vgg16_input = Input(shape = (size,size,channels))\n",
        "\n",
        "vgg = VGG16(input_tensor=vgg16_input, weights='imagenet', include_top=False)\n",
        "\n",
        "for layer in vgg.layers:\n",
        "\tlayer.trainable = False\n",
        "x = vgg(vgg16_input)\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "prediction = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model1 = Model(inputs = vgg16_input, outputs = prediction )\n",
        "model1.load_weights('/content/gdrive/MyDrive/project/vgg_0.36__preproccessed_loss.h5')\n",
        "y_model1_pred = model1.predict(X_test1)\n",
        "y_model1_pred_class = argmax(y_model1_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMiKmMqgJyOe"
      },
      "source": [
        "# VGG16 - model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDAuDvsFYPUg"
      },
      "source": [
        "model2 = Model(inputs = vgg16_input, outputs = prediction )\n",
        "model2.load_weights('/content/gdrive/MyDrive/project/vgg_0.41__preproccessed_loss.h5')\n",
        "\n",
        "y_model2_pred = model2.predict(X_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9362Lho8J0P-"
      },
      "source": [
        "# VGG16 - model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM3IAb0_IZt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e0ad13-e710-4daf-b641-0815128fbdf3"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "# re-size all the images to this\n",
        "# add preprocessing layer to the front of VGG\n",
        "vgg16_input = Input(shape = (size,size,channels))\n",
        "\n",
        "vgg = VGG16(input_tensor=vgg16_input, weights='imagenet', include_top=False)\n",
        "\n",
        "x = vgg(vgg16_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "prediction = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model3 = Model(inputs = vgg16_input, outputs = prediction )\n",
        "model3.load_weights('/content/gdrive/MyDrive/project/vgg_0.43__preproccessed_loss.h5')\n",
        "\n",
        "y_model3_pred = model3.predict(X_test1)\n",
        "print('Images Predicted until now:',len(y_model3_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images Predicted until now: 79726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_lzLwMJ4HF"
      },
      "source": [
        "# VGG16 - model 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BPJh_GRJ5co"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "# re-size all the images to this\n",
        "# add preprocessing layer to the front of VGG\n",
        "vgg16_input = Input(shape = (size,size,channels))\n",
        "\n",
        "vgg = VGG16(input_tensor=vgg16_input, weights='imagenet', include_top=False)\n",
        "# X_train2=preprocess_input(X_train)\n",
        "# X_val2=preprocess_input(X_val)\n",
        "x = vgg(vgg16_input)\n",
        "\n",
        "x = Flatten()(x)\n",
        "prediction = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model4 = Model(inputs = vgg16_input, outputs = prediction )\n",
        "model4.load_weights('/content/gdrive/MyDrive/project/vgg_0.45_loss.h5')\n",
        "\n",
        "y_model4_pred = model4.predict(X_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaaW_zgrSK2i"
      },
      "source": [
        "# Resnet50 - model 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VUENFruC0Fl"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "\n",
        "# X_train1=preprocess_input(X_train)\n",
        "# X_val1=preprocess_input(X_val) -these are not neccessary as "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNgtHgw4vpeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b3e4b8c-c3ce-4232-d2dc-c132ca55407c"
      },
      "source": [
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(128, 128, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
        "# # place the head FC model on top of the base model (this will become\n",
        "model5 = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-wbB-yhKQv6"
      },
      "source": [
        "model5.load_weights('/content/gdrive/MyDrive/project/resnet_0.4677_loss_preprocessed.h5')\n",
        "y_model5_pred = model5.predict(X_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8ypbS9kLuBg"
      },
      "source": [
        "# Resnet50 - model 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFF1OxRvL0K9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "\n",
        "# X_train1=preprocess_input(X_train)\n",
        "# X_val1=preprocess_input(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZqEQUR_L0K_"
      },
      "source": [
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(128, 128, 3)))\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(512, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
        "# # place the head FC model on top of the base model (this will become\n",
        "model6 = Model(inputs=baseModel.input, outputs=headModel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS-N_XuVL0LA"
      },
      "source": [
        "model6.load_weights('/content/gdrive/MyDrive/project/resnet_0.5_loss_preprocessed.h5')\n",
        "y_model6_pred = model6.predict(X_test1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q91iSSNNdTH3"
      },
      "source": [
        "y_model1_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model1_pred.pkl\") \n",
        "y_model2_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model2_pred.pkl\") \n",
        "y_model3_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model3_pred.pkl\") \n",
        "y_model4_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model4_pred.pkl\") \n",
        "y_model5_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model5_pred.pkl\") \n",
        "y_model6_pred=joblib.load(\"/content/gdrive/MyDrive/project/y_model6_pred.pkl\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFe13F_evXl4"
      },
      "source": [
        "# Mobilenet model 9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-DxFXjrvfqd"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import  preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "\n",
        "X_test2=joblib.load(\"/content/gdrive/MyDrive/project/X_test2.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Isy110qvfqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfaf50c4-6cb4-40e6-86ba-39fbe3351f94"
      },
      "source": [
        "baseModel = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3) )\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
        "# # place the head FC model on top of the base model (this will become\n",
        "# # the actual model we will train)\n",
        "model9 = Model(inputs=baseModel.input, outputs=headModel)\n",
        "model9.load_weights(\"/content/gdrive/MyDrive/project/mobilenet_0.3475_loss_preprocessed.h5\")\n",
        "y_model9_pred = model9.predict(X_test2)\n",
        "joblib.dump(y_model9_pred,\"/content/gdrive/MyDrive/project/y_model9_pred.pkl\")     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/MyDrive/project/y_model9_pred.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WysAIHv12bg"
      },
      "source": [
        "# Mobilenet model 10\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xGsdREF12bh"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import  preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWOVFfdL12bi"
      },
      "source": [
        "baseModel = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(128, 128, 3) )\n",
        "# construct the head of the model that will be placed on top of the\n",
        "# the base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "headModel = Flatten()(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(256, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(10, activation=\"softmax\")(headModel)\n",
        "# # place the head FC model on top of the base model (this will become\n",
        "# # the actual model we will train)\n",
        "model10 = Model(inputs=baseModel.input, outputs=headModel)\n",
        "model10.load_weights(\"/content/gdrive/MyDrive/project/mobilenet_0.3407_loss_preprocessed.h5\")\n",
        "\n",
        "y_model10_pred = model10.predict(X_test2)\n",
        "joblib.dump(y_model10_pred,\"/content/gdrive/MyDrive/project/y_model10_pred.pkl\")     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5kbLYujSekQ"
      },
      "source": [
        "# Mean Trimmed Ensembling \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdvJGhORSd1B"
      },
      "source": [
        "from statistics import mean\n",
        "# For Trimmed Mean\n",
        "ensemble_predictions = []\n",
        "predictions = []\n",
        "\n",
        "for i in range(len(X_test2)):\n",
        "    mean_prediction = []\n",
        "    average_pred=[]\n",
        "    for j in range(10):\n",
        "        predictions = []\n",
        "        predictions.append(y_model1_pred[i][j])\n",
        "        predictions.append(y_model2_pred[i][j])\n",
        "        predictions.append(y_model3_pred[i][j])\n",
        "        predictions.append(y_model4_pred[i][j])\n",
        "        predictions.append(y_model5_pred[i][j])\n",
        "        predictions.append(y_model6_pred[i][j])\n",
        "        predictions.append(y_model9_pred[i][j])\n",
        "        predictions.append(y_model10_pred[i][j])\n",
        "\n",
        "        trimmed_mean = (sum(predictions) - max(predictions) - min(predictions))/(len(predictions) - 2)\n",
        "        predictions = []\n",
        "        mean_prediction.append(trimmed_mean)\n",
        "\n",
        "\n",
        "    average_pred=average_pred/sum(average_pred)\n",
        "    mean_prediction = mean_prediction/ sum(mean_prediction)\n",
        "    ensemble_predictions.append(mean_prediction)\n",
        "        \n",
        "ensemble_predictions = array(ensemble_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26EGPdo2p0pa"
      },
      "source": [
        "joblib.dump(ensemble_predictions,\"/content/gdrive/MyDrive/project/ensemble_predictions.pkl\")     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWDx898SWFJY"
      },
      "source": [
        "# KNN on Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ij6H8R1l_Iwv"
      },
      "source": [
        "import pandas as pd\n",
        "test_data1 = pd.read_pickle('/content/gdrive/MyDrive/project/knn_test.pkl')\n",
        "data1=test_data1.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew5F4heP7lTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1f46a9-c8a1-4cdf-fad6-cfec7e7bad5c"
      },
      "source": [
        "data1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['img_85907.jpg',\n",
              "        array([22, 27, 21, ...,  7,  7,  5], dtype=uint8)],\n",
              "       ['img_24401.jpg',\n",
              "        array([11, 11,  8, ...,  8,  7,  3], dtype=uint8)],\n",
              "       ['img_18299.jpg',\n",
              "        array([38, 48, 37, ..., 23, 12, 14], dtype=uint8)],\n",
              "       ...,\n",
              "       ['img_37544.jpg',\n",
              "        array([66, 76, 60, ..., 10,  8,  9], dtype=uint8)],\n",
              "       ['img_7485.jpg',\n",
              "        array([28, 34, 20, ..., 43, 48, 56], dtype=uint8)],\n",
              "       ['img_31518.jpg',\n",
              "        array([38, 46, 31, ..., 44, 61, 80], dtype=uint8)]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gC82vD5ym4G",
        "outputId": "c1f3ac0e-4331-4c17-aa2c-eacf650746e4"
      },
      "source": [
        "data_dict=dict(( data1[i][0], data1[i][1]) for i in range(len(data1) ) )\n",
        "knn_input=array([data_dict[imgs[i]] for i in range(len(imgs))])  # To get knn_input in same order as imgs list\n",
        "knn_input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 21,  23,  18, ...,  11,   5,   5],\n",
              "       [ 22,  25,  16, ...,  22,  21,  19],\n",
              "       [248, 254, 254, ...,  31,  42,  35],\n",
              "       ...,\n",
              "       [ 21,  22,  17, ...,  18,  14,  15],\n",
              "       [ 28,  35,  25, ...,  36,  49,  62],\n",
              "       [ 13,  19,  13, ...,   9,   8,   4]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwVTW8VY8KkX"
      },
      "source": [
        "imgs= joblib.dump(knn_input,'/content/gdrive/MyDrive/project/knn_input.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlSfSgMx_IxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a89a2137-a5cf-45cb-edb5-809106f5ce01"
      },
      "source": [
        "plt.imshow(knn_input[10].reshape(30,40,3))\n",
        "plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 39.5, 29.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1rhog6O4PFS"
      },
      "source": [
        "# Install RAPIDS\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n",
        "\n",
        "import sys, os\n",
        "\n",
        "dist_package_index = sys.path.index('/usr/local/lib/python3.7/dist-packages')\n",
        "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.7/site-packages'] + sys.path[dist_package_index:]\n",
        "sys.path\n",
        "exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzg41CciDVWp"
      },
      "source": [
        "import joblib\n",
        "imgs=joblib.load( \"/content/gdrive/MyDrive/project/img_names.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by3i13dES1Pa"
      },
      "source": [
        "imgs=imgs.reshape(len(imgs),1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdyWG6QkDY-9"
      },
      "source": [
        "from cuml.neighbors import NearestNeighbors\n",
        "\n",
        "knn = NearestNeighbors(n_neighbors=15)\n",
        "knn.fit(knn_input)\n",
        "distances, indices1 = knn.kneighbors(knn_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWi7PhwqGKpV"
      },
      "source": [
        "knn_predictions = []\n",
        "predictions = []\n",
        "\n",
        "for i in range(indices1.shape[0]):\n",
        "    mean_prediction = []\n",
        "    for j in range(10):\n",
        "        for k in indices1[i]:\n",
        "            predictions.append(ensemble_predictions[k][j])\n",
        "        \n",
        "        trimmed_value = (sum(predictions) - max(predictions) - min(predictions))/(len(predictions) -2 )\n",
        "        mean_value = mean(predictions)\n",
        "        predictions = []\n",
        "        mean_prediction.append(trimmed_value)\n",
        "    \n",
        "    mean_prediction = mean_prediction/sum(mean_prediction)\n",
        "    knn_predictions.append(mean_prediction)\n",
        "            \n",
        "knn_predictions = array(knn_predictions)           "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOcPkg_7HDdu",
        "outputId": "e6c3fdef-2af8-4e08-e9d7-3a3eea008370"
      },
      "source": [
        "final = np.concatenate((imgs,knn_predictions),axis=1)\n",
        "final.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79726, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NB1KX24pwCS"
      },
      "source": [
        "# I got a log loss of 0.27773 with this prediction "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}